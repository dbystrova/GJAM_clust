---
title: "Readme"

output: rmarkdown::github_document
---

```{r global parameters, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE)
knitr::knit_engines$set(julia = JuliaCall::eng_juliacall)
library(repmis)
library(gjam)
library(MASS)
library(truncnorm)
library(coda)
library(RcppArmadillo)
library(arm)
library(Rcpp)
library(ggplot2)
library(AUC)
library(formattable)
library(mcclust.ext)
library(reshape2)
library(plyr)
library(dplyr)
library(gridExtra)
library(grid)
library(factoextra)
library(Hmsc)
library(knitr)
library(tidyverse)
library(corrplot)
library(rootSolve)
library(FactoMineR)
library(ggsci)

Rcpp::sourceCpp('src/cppFns.cpp')
source("R/gjamHfunctions.R")
source("R/gjam.R")

```

## Introduction

In the dimension reduction approach in the GJAM model, the species are clustered in their dependence behavior.
In the extended model we can use the prior knowledge on the number of clusters in the GJAM model and obtain the cluster estimates.

## Reproduce the results 

To reproduce the analysis results, there are two possibilites:

1. Run the fit_script.R, which will run and save the models in the folder "PCA analysis". This option could be time consuming.
2. Download saved models from the following link [models](https://drive.google.com/open?id=1sRu7Q7rJ4aIYp-YCKOa_igA5Ofzc7tRH)
and load the models in the folder "PCA analysis/r5_models/chain_1"(2) on your local repository

The analysis results could be reproduced by the "analysis.R" script.  
**to run specifc functions for now use firstly script inlclude.R**

## How to use the functions

Firstly, we describe the initial GJAM model and then describe how to specify the parameters for the prior. Full description of the GJAM model is provided in the GJAM package documentation and [vignette](https://cran.r-project.org/web/packages/gjam/vignettes/gjamVignette.html)

Dimension reduction in GJAM model was proposed by [Taylor et el 2018]. 
Dimension reduction is used in two ways:

* When dataset contains more species than can be fitted given sample size $n$.\

* When the number of species $S$ is too large.\

The first case is used with default parameters. For the second case we need to specify the parameters for dimension `reduction` in `reductList` and 
add this parameters in the `modelList`. 


```{r description, include=TRUE, echo=TRUE, warning=FALSE,eval = F}
load("Bauges_plant.Rdata")
y<- Bauges_plant[,3:(ncol(Bauges_plant))]
Y_data<- gjamTrimY(y,20)$y  ## trim the species that occur less then in 20 cites
X_data <- Bauges_plant[,1:2] # environmental covariates
S<- ncol(Y_data)  # number of species
formula <- as.formula( ~   PC1  + PC2 + I(PC1^2) + I(PC2^2))
iterations=50# number of iterations
burn_period=10  # burn-in period
r_reduct = 5      # rank of the covariance matrix approximation
```


For the standard dimension reduction regime in GJAM model version, parameters for `reducltList` and  `modelList` need to be specified.
In the `reducltList`

 * N is maximum number of possible clusters. $N \leq S$. Could be limited for $S$ large to 150. (Technically: the truncation number in Dirichlet Multinomial process)  
 * r is the number of latent factors. $r \leq S$.   

In the `'modelList'`

 * `typeNames` - specify the type of response data  
 * `ng` is the number of iterations  
 * `reductList` is the parameters for the dimension reduction  

```{r fit, include=TRUE, echo=TRUE, warning=FALSE,eval = F}
rl <- list(r =r_reduct, N = S)
ml   <- list(ng = iterations, burnin = burn_period, typeNames = 'PA', reductList = rl,PREDICTX = F)
fit<-gjam(formula, xdata = X_data, ydata = Y_data, modelList = ml)
```

To incorporate prior knowledge in the model, we firstly speciify, the Bayesian nonparametric prior in the variable `DRtype` (see Table 1)

Then `reducltList` in this case will be
In the `reducltList`

 * `N` is maximum number of possible clusters. $N \leq S$
 * `r` is the number of latent factors. $r \leq S$. 
 * `DRtype` is the type of the Baysian nonparametric prior.
 * `K` is prior number of clusters

For the Pitman--Yor process as there are two parameters PY$(\alpha, \sigma)$, we specify the desired value of  $\sigma \in (0,1)$. (in the current implementation).

**Table 1. Dimension reduction types**

`DRtype` | Process type  | Parameters | Priors on parameters| Parameters to specify
:----: | :-------: | :----------: | :----------------------------: | -----------------
`'-'`  | Dirichlet| $\alpha$ | none | none
`'1'`  | Dirichlet| $\alpha$ | $\text{Ga}(\nu_1,\nu_2)$ | prior number of clusters K
`'2'`  | Pitman--Yor | $(\alpha, \sigma)$ | none | prior number of clusters K


More precisely on the values of the parameter `DRtype`:

  * No value specified, then the model will use standard dimension reduction approach.
  * `1` is the dimension reduction with the Dirichlet process and prior distribution on the concentration parameter $\alpha$
  * `2` is the dimension reduction with the Pitman--Yor process with fixed parameters $\alpha$ and $\sigma$. 

For the example, in the **Bauges plant dataset ** , we take as a prior number of plant functional groups which is $16$.  If we want to take the Dirichlet process, then we use the following parameters for the `reductList`. Here, `DRtype =1`.   The choice of $N$ is equal to $S$ is natural, as we consider any possible clustering and $K$ is prior number of clusters.
 
```{r fit DR1, include=TRUE, echo=TRUE, warning=FALSE,eval = F}
rl1  <- list(r = r_reduct, N = S ,DRtype="1", K=16)  #prior is number of plant functional groups
```

For the Pitman--Yor process .Here, `DRtype =2` and we specify `K`,and value of  $\sigma =0.5$  and the choice of $N$ is the same. 

```{r fit PY1, include=TRUE, echo=TRUE, warning=FALSE,eval = F}
rl2  <- list(r = r_reduct, N = S ,DRtype="2", K=16)  #prior is number of plant functional groups
```

For instance, we fit the model with the first specification

```{r fit_all, include=TRUE, echo=TRUE, warning=FALSE,eval = F}
ml1   <- list(ng = iterations, burnin = burn_period, typeNames = 'PA', reductList = rl1,PREDICTX = F)
fit1<-gjam(formula, xdata = X_data, ydata = Y_data, modelList = ml1)
```


We get the `fit1` gjam object. This object is the same as the one from the original model, except several additional parameters.

The function `gjjamCluster` estimates the optimal cluster,that summarize posterior cluster distribution. The function is build using the `GreedyEPL` package by \[Rastelli et al.\]. It takes as the input 
*  gjam object fitted model
 * K possible number of clusters for initialization of greedy search algorithm  
 * Clustering used for prior specification
 
* last two options are used to set the initial clustering for the algorithm that estimate the optimal clustering.
 
This function return the values  

 * VI_list list of the estimated clusters, corresponding to the given starting points
 * EPL_value  list of the loss function values for the given starting points

The estimated cluster with the smallest EPL_value  best represent the posterior clustering distribution.
```{r cluster, include=TRUE, echo=TRUE, warning=FALSE, eval=F}
```

